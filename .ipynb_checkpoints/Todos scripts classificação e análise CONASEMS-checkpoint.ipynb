{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209876f4-4dd0-4844-ae16-312905daf38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1 classificação e análise CONASEMS - listar os de termos de filtragem em cada um dos trabalhos selecionados\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Listas de padrões para busca\n",
    "patterns = [\n",
    "    r'4G', r'\\b4G\\b', r'\\(4G\\)', r'5G', r'\\b5G\\b', r'\\(5G\\)', r'\\bAI\\b', r'\\(AI\\)', r'\\bIA\\b', r'\\(IA\\)', \n",
    "    r'aplicativo', r'\\bAPI\\b', r'\\(API\\)', r'aprendizado de máquina', r'aprendizagem profunda', r'assistente virtual', \n",
    "    r'augmented reality', r'automação', r'big data', r'Bluetooth', r'blockchain', r'celular', r'celulares', r'chatbot', \n",
    "    r'chatgpt', r'cloud', r'computação cognitiva', r'computação ubíqua', r'conectividade', r'curso autoinstrucional', \n",
    "    r'cursos massivos online', r'dashboard', r'dados massivos', r'data lake', r'data mining', r'datacenter', r'deep learning', \n",
    "    r'device', r'dispositivo portátil', r'\\bEAD\\b', r'\\(EAD\\)', r'e-learning', r'e-saúde', r'ehealth', r'ensino à distância', \n",
    "    r'\\bERP\\b', r'\\(ERP\\)', r'Enterprise Resource Planning', r'\\bESP32\\b', r'\\(ESP32\\)', r'facebook', r'gamificação', \n",
    "    r'geoprocessamento', r'georreferenciamento', r'geotecnologia', r'grande modelo de linguagem', r'grandes modelos de linguagem', \n",
    "    r'instagram', r'interface digital', r'internet', r'internet das coisas', r'interoperabilidade', r'intervenção digital', \n",
    "    r'inteligente', r'inteligência artificial', r'inteligência aumentada', r'\\bIoT\\b', r'\\(IoT\\)', r'large language model', \n",
    "    r'\\bllm\\b', r'\\(llm\\)', r'machine learning', r'mhealth', r'mídia social', r'mídias sociais', r'mixed reality', \n",
    "    r'mobile', r'MOOC', r'\\bMicrocontrolador\\b', r'\\(Microcontrolador\\)', r'nuvem', r'painel de indicador', \n",
    "    r'painel de indicadores', r'painéis de indicador', r'painéis de indicadores', r'planilha', r'plataforma', r'PowerBI', \n",
    "    r'PowerPoint', r'prontuário eletrônico', r'privacidade de dados', r'proteção de dados', r'raspberry', \n",
    "    r'realidade aumentada', r'realidades aumentadas', r'realidade mista', r'realidades mistas', r'realidade virtual', \n",
    "    r'realidades virtuais', r'rede móvel', r'rede neural', r'rede social', r'redes sociais', r'resolução digital', \n",
    "    r'robótica', r'\\bSIG\\b', r'\\(SIG\\)', r'saúde móvel', r'segurança digital', r'sensor', r'sensores', \n",
    "    r'sistema de gestão de saúde', r'sistemas de gestão de saúde', r'sistema de informação', r'sistemas de informação', \n",
    "    r'sistema de informações', r'sistemas de informações', r'sistema digital', r'sistemas digitais', r'site', r'smartphone', \n",
    "    r'smartphones', r'solução digital', r'soluções digitais', r'software', r'tecnologia', r'tecnologias', r'teleassistência', \n",
    "    r'teleatendimento', r'telecirurgia', r'teleconsulta', r'teleconsultoria', r'telediagnóstico', r'teleeducação', \n",
    "    r'tele-espirometria', r'telefônica', r'telefone', r'telegram', r'telemedicina', r'telemonitoramento', r'teleorientação', \n",
    "    r'telepsicologia', r'telerradiologia', r'telespirometria', r'telessaúde', r'tele-saúde', r'teletriagem', \n",
    "    r'televigilância', r'transformação digital', r'transformações digitais', r'vídeogame', r'vídeogames', r'video', \n",
    "    r'videos', r'virtual', r'web', r'website', r'Whats', r'Watts', r'Whatts', \n",
    "    r'\\bPEC\\b', r'\\(PEC\\)', r'\\bPEC-SUS\\b', r'\\(PEC-SUS\\)', r'\\bE-SUS\\b', r'\\(E-SUS\\)', r'\\besus\\b', r'\\(esus\\)'\n",
    "]\n",
    "\n",
    "# Compilar padrões de regex para eficiência\n",
    "compiled_patterns = [re.compile(pat, re.IGNORECASE) for pat in patterns]\n",
    "\n",
    "# Função para limpar os padrões removendo \\b, parênteses e barras invertidas\n",
    "def clean_pattern(pattern):\n",
    "    return re.sub(r'\\\\b|\\\\|\\(|\\)', '', pattern)\n",
    "\n",
    "# Função para identificar e listar padrões únicos encontrados em cada resumo\n",
    "def extract_unique_patterns(text):\n",
    "    matches = set()  # Usar set para garantir unicidade\n",
    "    \n",
    "    # Usar re.sub com uma função lambda para capturar padrões limpos\n",
    "    for pattern in compiled_patterns:\n",
    "        re.sub(pattern, lambda m: matches.add(clean_pattern(pattern.pattern)), text)\n",
    "    \n",
    "    return list(matches)  # Converte para lista antes de salvar\n",
    "\n",
    "# Carregar o arquivo Excel\n",
    "df_selecionadas = pd.read_excel(\"experiencias_selecionadas_CONASEMS.xlsx\")\n",
    "\n",
    "# Inicializar a coluna 'tipos_tecnologia' com listas vazias\n",
    "df_selecionadas[\"tipos_tecnologia\"] = [[] for _ in range(len(df_selecionadas))]\n",
    "\n",
    "# Iterar sobre o DataFrame para extrair padrões únicos\n",
    "for idx, linha in df_selecionadas.iterrows():\n",
    "    resumo_completo = linha[\"resumo_completo\"]\n",
    "    \n",
    "    # Obter lista de padrões únicos encontrados\n",
    "    unique_patterns = extract_unique_patterns(resumo_completo)\n",
    "    \n",
    "    # Atualizar a coluna 'tipos_tecnologia' com os padrões encontrados\n",
    "    df_selecionadas.at[idx, \"tipos_tecnologia\"] = unique_patterns\n",
    "\n",
    "# Salvar o DataFrame atualizado\n",
    "df_selecionadas.to_excel(\"experiencias_selecionadas_tipos_tecnologia_CONASEMS.xlsx\", index=False)\n",
    "df_selecionadas.to_csv(\"experiencias_selecionadas_tipos_tecnologia_CONASEMS.csv\", index=False)\n",
    "df_selecionadas.to_json(\"experiencias_selecionadas_tipos_tecnologia_CONASEMS.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbacffd-71c0-429f-a238-dd65218ed2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 2 classificação e análise CONASEMS - contagem da ocorrência de trabalhos que contém os termos de busca e ordenamento dos \n",
    "# termos mais utilizados\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "# Carregar o arquivo CSV com os trabalhos e tipos de tecnologia\n",
    "df_selecionadas = pd.read_csv(\"experiencias_selecionadas_tipos_tecnologia_CONASEMS.csv\")\n",
    "\n",
    "# Converter a coluna 'tipos_tecnologia' de string para lista, se necessário\n",
    "df_selecionadas['tipos_tecnologia'] = df_selecionadas['tipos_tecnologia'].apply(ast.literal_eval)\n",
    "\n",
    "# Carregar o arquivo de correlação entre termos e temas\n",
    "df_correlacao = pd.read_excel(\"correlacao_termos_temas.xlsx\")\n",
    "df_correlacao = df_correlacao.sort_values(by='termo').reset_index(drop=True)\n",
    "\n",
    "# Anos presentes no DataFrame\n",
    "anos = [2018, 2019, 2021, 2022]\n",
    "\n",
    "# Dicionários para armazenar contagens por ano\n",
    "contagem_termos_por_ano = {ano: Counter() for ano in anos}\n",
    "contagem_temas_por_ano = {ano: Counter() for ano in anos}\n",
    "contagem_termos_total = Counter()\n",
    "\n",
    "# Iterar pelos anos para calcular as frequências\n",
    "for ano in anos:\n",
    "    # Filtrar o DataFrame para o ano específico\n",
    "    df_ano = df_selecionadas[df_selecionadas[\"ano\"] == ano]\n",
    "    \n",
    "    # Unificar todas as listas de 'tipos_tecnologia' para o ano\n",
    "    todos_tipos = sum(df_ano['tipos_tecnologia'], [])\n",
    "    \n",
    "    # Contar a frequência de cada valor único para o ano específico\n",
    "    contagem_termos_por_ano[ano] = Counter(todos_tipos)\n",
    "    \n",
    "    # Atualizar o contador total\n",
    "    contagem_termos_total.update(todos_tipos)\n",
    "    \n",
    "    # Adicionar o tema a cada termo e contar a frequência dos temas\n",
    "    for termo, frequencia in contagem_termos_por_ano[ano].items():\n",
    "        tema = df_correlacao[df_correlacao['termo'] == termo]['tema'].values[0] if termo in df_correlacao['termo'].values else 'Desconhecido'\n",
    "        contagem_temas_por_ano[ano][tema] += frequencia\n",
    "\n",
    "# Criar o DataFrame para Contagem de Termos com colunas para cada ano\n",
    "df_contagem_termos = pd.DataFrame()\n",
    "df_contagem_termos['Tipo de Tecnologia'] = df_correlacao['termo']\n",
    "for ano in anos:\n",
    "    df_contagem_termos[f'{ano}'] = df_contagem_termos['Tipo de Tecnologia'].apply(lambda termo: contagem_termos_por_ano[ano].get(termo, 0))\n",
    "df_contagem_termos['Total'] = df_contagem_termos['Tipo de Tecnologia'].apply(lambda termo: contagem_termos_total.get(termo, 0))\n",
    "\n",
    "# Criar o DataFrame para Contagem de Temas com colunas para cada ano\n",
    "df_contagem_temas = pd.DataFrame()\n",
    "df_contagem_temas['Tema'] = df_correlacao['tema'].unique()\n",
    "for ano in anos:\n",
    "    df_contagem_temas[f'{ano}'] = df_contagem_temas['Tema'].apply(lambda tema: contagem_temas_por_ano[ano].get(tema, 0))\n",
    "df_contagem_temas['Total'] = df_contagem_temas[[f'{ano}' for ano in anos]].sum(axis=1)\n",
    "\n",
    "# Criar a nova tabela com a lista de termos por tema e frequência total de cada tema e ano\n",
    "lista_termos_por_tema = []\n",
    "for tema in df_contagem_temas['Tema']:\n",
    "    termos_por_ano = {}\n",
    "    frequencias_por_ano = {}\n",
    "    for ano in anos:\n",
    "        # Obter termos e frequências e ordenar por frequência\n",
    "        termos_ano = [f\"{termo} ({contagem_termos_por_ano[ano][termo]})\" for termo in df_correlacao[df_correlacao['tema'] == tema]['termo'] if contagem_termos_por_ano[ano].get(termo, 0) > 0]\n",
    "        termos_ano_sorted = sorted(termos_ano, key=lambda x: int(x.split('(')[-1].strip(')')), reverse=True)\n",
    "        termos_por_ano[f'Termos {ano}'] = ', '.join(termos_ano_sorted)\n",
    "        frequencias_por_ano[f'{ano}'] = contagem_temas_por_ano[ano].get(tema, 0)\n",
    "    \n",
    "    # Calcular os termos totais (soma de todas as frequências) e ordenar\n",
    "    termos_total = [f\"{termo} ({contagem_termos_total[termo]})\" for termo in df_correlacao[df_correlacao['tema'] == tema]['termo'] if contagem_termos_total.get(termo, 0) > 0]\n",
    "    termos_total_sorted = ', '.join(sorted(termos_total, key=lambda x: int(x.split('(')[-1].strip(')')), reverse=True))\n",
    "    frequencia_total = sum(frequencias_por_ano.values())\n",
    "    \n",
    "    lista_termos_por_tema.append({\n",
    "        'Tema': tema,\n",
    "        **termos_por_ano,\n",
    "        'Termos Total': termos_total_sorted,\n",
    "        **frequencias_por_ano,\n",
    "        'Total': frequencia_total\n",
    "    })\n",
    "\n",
    "df_lista_termos_por_tema = pd.DataFrame(lista_termos_por_tema)\n",
    "\n",
    "# Ordenar as tabelas conforme solicitado\n",
    "df_contagem_termos = df_contagem_termos.sort_values(by='Total', ascending=False).reset_index(drop=True)\n",
    "df_contagem_temas = df_contagem_temas.sort_values(by='Total', ascending=False).reset_index(drop=True)\n",
    "df_lista_termos_por_tema = df_lista_termos_por_tema.sort_values(by='Total', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Salvar em um arquivo Excel com as 4 planilhas:\n",
    "# 1) Correlação de Termos e Temas\n",
    "# 2) Contagem de Termos\n",
    "# 3) Contagem de Temas\n",
    "# 4) Lista de Termos por Tema e Frequência Total\n",
    "with pd.ExcelWriter(\"contagem_termos_e_temas_por_ano_final.xlsx\") as writer:\n",
    "    df_correlacao.to_excel(writer, sheet_name=\"Correlação de Termos e Temas\", index=False)\n",
    "    df_contagem_termos.to_excel(writer, sheet_name=\"Contagem de Termos\", index=False)\n",
    "    df_contagem_temas.to_excel(writer, sheet_name=\"Contagem de Temas\", index=False)\n",
    "    df_lista_termos_por_tema.to_excel(writer, sheet_name=\"Lista de Termos por Tema\", index=False)\n",
    "\n",
    "# Exibir os DataFrames resultantes\n",
    "print(\"Contagem de Termos:\")\n",
    "print(df_contagem_termos)\n",
    "print(\"\\nContagem de Temas:\")\n",
    "print(df_contagem_temas)\n",
    "print(\"\\nLista de Termos por Tema e Frequência Total:\")\n",
    "print(df_lista_termos_por_tema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e918df04-5e8e-457b-9417-e37994b64d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_uf: ['id', 'sigla', 'nome', 'regiao_id', 'regiao_sigla', 'regiao_nome']\n",
      "df_cidades: ['id_cidade', 'nome', 'microrregiao_id', 'microrregiao_nome', 'microrregiao_mesorregiao.id', 'microrregiao_mesorregiao.nome', 'id_uf', 'sigla_uf', 'microrregiao_mesorregiao.UF.nome', 'microrregiao_mesorregiao.UF.regiao.id', 'microrregiao_mesorregiao.UF.regiao.sigla', 'microrregiao_mesorregiao.UF.regiao.nome', 'ri_id', 'ri_nome', 'ri_regiao-intermediaria.id', 'ri_regiao-intermediaria.nome', 'ri_regiao-intermediaria.UF.id', 'ri_regiao-intermediaria.UF.sigla', 'ri_regiao-intermediaria.UF.nome', 'ri_regiao-intermediaria.UF.regiao.id', 'regiao_sigla', 'regiao_nome']\n",
      "df_estudos: ['id', 'titulo', 'cidade', 'uf', 'ano', 'autoria', 'coautoria', 'resumo_completo', 'resumo_completo_html', 'introducao', 'objetivos', 'metodologia', 'resultados', 'conclusoes', 'palavras_chave', 'link_experiencia', 'id_cidade', 'id_uf', 'regiao_sigla', 'regiao_nome']\n"
     ]
    }
   ],
   "source": [
    "# Parte 3 classificação e análise CONASEMS - categorização dos dados por UF e região\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o JSON de cidades\n",
    "df_cidades = pd.read_json(\"https://servicodados.ibge.gov.br/api/v1/localidades/municipios\")\n",
    "\n",
    "# Normalizar as colunas 'microrregiao' e 'regiao-imediata' para expandir seus dicionários em colunas separadas\n",
    "df_cidades_mr = pd.json_normalize(df_cidades[\"microrregiao\"])\n",
    "df_cidades_ri = pd.json_normalize(df_cidades[\"regiao-imediata\"])\n",
    "\n",
    "# Remover as colunas originais e juntar as normalizadas com prefixos apropriados\n",
    "df_cidades = df_cidades.drop(columns=[\"microrregiao\", \"regiao-imediata\"]).join(\n",
    "    df_cidades_mr.add_prefix(\"microrregiao_\")\n",
    ").join(\n",
    "    df_cidades_ri.add_prefix(\"ri_\")\n",
    ")\n",
    "\n",
    "# Carregar o JSON de unidades federativas (UF)\n",
    "df_uf = pd.read_json(\"https://servicodados.ibge.gov.br/api/v1/localidades/estados\")\n",
    "\n",
    "# Normalizar a coluna 'regiao' para expandir seu dicionário em colunas separadas\n",
    "df_uf_rg = pd.json_normalize(df_uf[\"regiao\"])\n",
    "\n",
    "# Remover a coluna original e juntar a normalizada com prefixo apropriado\n",
    "df_uf = df_uf.drop(columns=\"regiao\").join(df_uf_rg.add_prefix('regiao_'))\n",
    "\n",
    "# Ajuste da coluna 'id' em df_cidades para evitar duplicação no merge\n",
    "df_cidades = df_cidades.rename(columns={'id': 'id_cidade'})\n",
    "\n",
    "# Carregar df_estudos\n",
    "df_estudos = pd.read_json(\"experiencias_selecionadas_CONASEMS.json\")\n",
    "\n",
    "# Substituir \"Brasilia\" por \"Brasília\" na coluna 'cidade'\n",
    "df_estudos['cidade'] = df_estudos['cidade'].replace(\"Brasilia\", \"Brasília\")\n",
    "\n",
    "# Corrigir o nome da cidade em df_estudos\n",
    "#df_estudos['cidade'] = df_estudos['cidade'].replace(\"Brasilia\", \"Brasília\")\n",
    "\n",
    "# Adicionar a sigla do UF ao df_cidades para facilitar o merge\n",
    "df_cidades = df_cidades.rename(columns={'microrregiao_mesorregiao.UF.sigla': 'sigla_uf', \n",
    "                                        'microrregiao_mesorregiao.UF.id': 'id_uf', \n",
    "                                        'ri_regiao-intermediaria.UF.regiao.sigla': 'regiao_sigla', \n",
    "                                        'ri_regiao-intermediaria.UF.regiao.nome': 'regiao_nome'})\n",
    "\n",
    "# Fazer o merge usando a combinação de cidade e estado\n",
    "df_estudos = df_estudos.merge(\n",
    "    df_cidades[['nome', 'sigla_uf', 'id_cidade', 'id_uf', 'regiao_sigla', 'regiao_nome']],\n",
    "    left_on=['cidade', 'estado'],\n",
    "    right_on=['nome', 'sigla_uf'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Renomear as colunas conforme necessário\n",
    "df_estudos = df_estudos.rename(columns={'estado': 'uf'})\n",
    "\n",
    "# Remover colunas extras resultantes do merge\n",
    "df_estudos = df_estudos.drop(columns=['nome', 'sigla_uf'])\n",
    "\n",
    "# Salvar em JSON\n",
    "df_estudos.to_json(\"experiencias_selecionadas_infos_geograficas_CONASEMS.json\", index=False)\n",
    "\n",
    "anos = sorted(df_estudos['ano'].unique())\n",
    "\n",
    "# Tabela 1: UF, Região, Frequência por ano e Total\n",
    "# Agrupar por UF, Região e Ano para contar a frequência de 'id'\n",
    "df_uf_regiao = df_estudos.groupby(['uf', 'regiao_nome', 'ano']).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "# Renomear colunas para que cada coluna do ano seja apenas o ano (sem prefixo)\n",
    "df_uf_regiao.columns.name = None  # Remove o nome do índice da coluna\n",
    "df_uf_regiao.columns = ['UF', 'Região'] + [str(ano) for ano in anos]\n",
    "\n",
    "# Adicionar coluna 'Total' com a soma das frequências por linha\n",
    "df_uf_regiao['Total'] = df_uf_regiao[[str(ano) for ano in anos]].sum(axis=1)\n",
    "\n",
    "# Ordenar por Região e depois por UF de forma ascendente\n",
    "df_uf_regiao = df_uf_regiao.sort_values(by=['Região', 'UF']).reset_index(drop=True)\n",
    "\n",
    "# Exibir a primeira tabela\n",
    "print(\"Tabela 1: UF, Região e Frequência por Ano\")\n",
    "print(df_uf_regiao)\n",
    "\n",
    "# Tabela 2: Região e Frequência por ano e Total\n",
    "# Agrupar por Região e Ano para contar a frequência de 'id'\n",
    "df_regiao = df_estudos.groupby(['regiao_nome', 'ano']).size().unstack(fill_value=0).reset_index()\n",
    "\n",
    "# Renomear colunas para que cada coluna do ano seja apenas o ano\n",
    "df_regiao.columns.name = None\n",
    "df_regiao.columns = ['Região'] + [str(ano) for ano in anos]\n",
    "\n",
    "# Adicionar coluna 'Total' com a soma das frequências por linha\n",
    "df_regiao['Total'] = df_regiao[[str(ano) for ano in anos]].sum(axis=1)\n",
    "\n",
    "# Ordenar por Região de forma ascendente\n",
    "df_regiao = df_regiao.sort_values(by='Região').reset_index(drop=True)\n",
    "\n",
    "# Exibir a segunda tabela\n",
    "print(\"\\nTabela 2: Região e Frequência por Ano\")\n",
    "print(df_regiao)\n",
    "\n",
    "# Caso queira salvar ambas as tabelas em um arquivo Excel\n",
    "with pd.ExcelWriter(\"tabelas_frequencia_por_ano.xlsx\") as writer:\n",
    "    df_uf_regiao.to_excel(writer, sheet_name=\"UF_Regiao_Frequencia\", index=False)\n",
    "    df_regiao.to_excel(writer, sheet_name=\"Regiao_Frequencia\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4488721-4443-40e2-9d14-98776f79c09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Todos os estudos</th>\n",
       "      <th>Estudos selecionados</th>\n",
       "      <th>Percentual de selecionados</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ano</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>346</td>\n",
       "      <td>25</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>500</td>\n",
       "      <td>32</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>630</td>\n",
       "      <td>167</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>337</td>\n",
       "      <td>47</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Todos os estudos  Estudos selecionados  Percentual de selecionados\n",
       "Ano                                                                     \n",
       "2018               346                    25                       0.072\n",
       "2019               500                    32                       0.064\n",
       "2021               630                   167                       0.265\n",
       "2022               337                    47                       0.139"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parte 4 classificação e análise CONASEMS - proporção de estudos sobre tecnologia digital em saúde por ano\n",
    "\n",
    "import pandas as pd\n",
    "df_geral = pd.read_json(\"experiencias_completas_CONASEMS.json\")\n",
    "df_selecionado = pd.read_json(\"experiencias_selecionadas_CONASEMS.json\")\n",
    "\n",
    "df_geral = df_geral.rename(columns={\"ano\": \"Ano\"})\n",
    "df_selecionado = df_selecionado.rename(columns={\"ano\": \"Ano\"})\n",
    "\n",
    "df_ano_geral = df_geral[[\"Ano\", \"id\"]].groupby(\"Ano\").count().rename(columns={\"id\": \"Todos os estudos\"})\n",
    "df_ano_selecionado = df_selecionado[[\"Ano\", \"id\"]].groupby(\"Ano\").count().rename(columns={\"id\": \"Estudos selecionados\"})\n",
    "\n",
    "# Junta os DataFrames com base na coluna 'ano'\n",
    "df_combinado = pd.merge(df_ano_geral, df_ano_selecionado, on=\"Ano\", how=\"outer\")\n",
    "\n",
    "\n",
    "# Calcula a coluna '%' com a proporção arredondada para 2 decimais\n",
    "df_combinado['Percentual de selecionados'] = (df_combinado['Estudos selecionados'] / df_combinado['Todos os estudos']).round(3)\n",
    "\n",
    "# Mostra o resultado\n",
    "# df_combinado.to_excel(\"proporcao_estudos_selecionados_ano.xlsx\", index=False)\n",
    "\n",
    "df_combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0493de-f3a4-4137-8456-67d3895875c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
